@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
   publisher = {American Psychological Association},
   address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}}

@misc{kunchukuttan2020indicnlp,
author = "Anoop Kunchukuttan",
title = "{The IndicNLP Library}",
year = "2020",
howpublished={\url{https://github.com/anoopkunchukuttan/indic_nlp_library/blob/master/docs/indicnlp.pdf}}
}

@Misc{johnson2014,
author = {Johnson, Kyle P.},
title = {{CLTK}: The {C}lassical {L}anguage {T}oolkit},
howpublished = {\url{https://github.com/cltk/cltk}},
year = {2014},
}

@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@article{eisner2016emoji2vec,
  title={emoji2vec: Learning emoji representations from their description},
  author={Eisner, Ben and Rockt{\"a}schel, Tim and Augenstein, Isabelle and Bo{\v{s}}njak, Matko and Riedel, Sebastian},
  journal={arXiv preprint arXiv:1609.08359},
  year={2016}
}

@article{outsios2019evaluation,
  title={Evaluation of Greek Word Embeddings},
  author={Outsios, Stamatis and Karatsalos, Christos and Skianis, Konstantinos and Vazirgiannis, Michalis},
  journal={arXiv preprint arXiv:1904.04032},
  year={2019}
}

@inproceedings{sprugnoli2019vir,
  title={Vir is to Moderatus as Mulier is to Intemperans-Lemma Embeddings for Latin.},
  author={Sprugnoli, Rachele and Passarotti, Marco and Moretti, Giovanni},
  booktitle={CLiC-it},
  year={2019}
}

@inproceedings{elrazzaz2017methodical,
  title={Methodical evaluation of Arabic word embeddings},
  author={Elrazzaz, Mohammed and Elbassuoni, Shady and Shaban, Khaled and Helwe, Chadi},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={454--458},
  year={2017}
}

@inproceedings{agrawal2018learning,
  title={Learning emotion-enriched word representations},
  author={Agrawal, Ameeta and An, Aijun and Papagelis, Manos},
  booktitle={Proceedings of the 27th International Conference on Computational Linguistics},
  pages={950--961},
  year={2018}
}







@article{grave2018learning,
  title={Learning word vectors for 157 languages},
  author={Grave, Edouard and Bojanowski, Piotr and Gupta, Prakhar and Joulin, Armand and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1802.06893},
  year={2018}
}

@article{al2013polyglot,
  title={Polyglot: Distributed word representations for multilingual nlp},
  author={Al-Rfou, Rami and Perozzi, Bryan and Skiena, Steven},
  journal={arXiv preprint arXiv:1307.1662},
  year={2013}
}

@article{hamilton2016diachronic,
  title={Diachronic word embeddings reveal statistical laws of semantic change},
  author={Hamilton, William L and Leskovec, Jure and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1605.09096},
  year={2016}
}

@inproceedings{hamilton2016cultural,
  title={Cultural shift or linguistic drift? comparing two computational measures of semantic change},
  author={Hamilton, William L and Leskovec, Jure and Jurafsky, Dan},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing. Conference on Empirical Methods in Natural Language Processing},
  volume={2016},
  pages={2116},
  year={2016},
  organization={NIH Public Access}
}

@article{kutuzov2018diachronic,
  title={Diachronic word embeddings and semantic shifts: a survey},
  author={Kutuzov, Andrey and {\O}vrelid, Lilja and Szymanski, Terrence and Velldal, Erik},
  journal={arXiv preprint arXiv:1806.03537},
  year={2018}
}

@inproceedings{yin2018dimensionality,
  title={On the dimensionality of word embedding},
  author={Yin, Zi and Shen, Yuanyuan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={887--898},
  year={2018}
}

@article{kozlowski2019geometry,
  title={The geometry of culture: Analyzing the meanings of class through word embeddings},
  author={Kozlowski, Austin C and Taddy, Matt and Evans, James A},
  journal={American Sociological Review},
  volume={84},
  number={5},
  pages={905--949},
  year={2019},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@inproceedings{dubossarsky2017outta,
  title={Outta control: Laws of semantic change and inherent biases in word representation models},
  author={Dubossarsky, Haim and Weinshall, Daphna and Grossman, Eitan},
  booktitle={Proceedings of the 2017 conference on empirical methods in natural language processing},
  pages={1136--1145},
  year={2017}
}

@article{tang2018state,
  title={A state-of-the-art of semantic change computation},
  author={Tang, Xuri},
  journal={arXiv preprint arXiv:1801.09872},
  year={2018}
}

@inproceedings{szymanski2017temporal,
  title={Temporal word analogies: Identifying lexical replacement with diachronic word embeddings},
  author={Szymanski, Terrence},
  booktitle={Proceedings of the 55th annual meeting of the association for computational linguistics (volume 2: short papers)},
  pages={448--453},
  year={2017}
}

@inproceedings{liang2018dynamic,
  title={Dynamic embeddings for user profiling in twitter},
  author={Liang, Shangsong and Zhang, Xiangliang and Ren, Zhaochun and Kanoulas, Evangelos},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1764--1773},
  year={2018}
}

@article{chen2017understanding,
  title={Understanding the topic evolution in a scientific domain: An exploratory study for the field of information retrieval},
  author={Chen, Baitong and Tsutsui, Satoshi and Ding, Ying and Ma, Feicheng},
  journal={Journal of Informetrics},
  volume={11},
  number={4},
  pages={1175--1189},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{azarbonyad2017words,
  title={Words are malleable: Computing semantic shifts in political and media discourse},
  author={Azarbonyad, Hosein and Dehghani, Mostafa and Beelen, Kaspar and Arkut, Alexandra and Marx, Maarten and Kamps, Jaap},
  booktitle={Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
  pages={1509--1518},
  year={2017}
}

@inproceedings{gonen2020simple,
  title={Simple, Interpretable and Stable Method for Detecting Words with Usage Change across Corpora},
  author={Gonen, Hila and Jawahar, Ganesh and Seddah, Djam{\'e} and Goldberg, Yoav},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={538--555},
  year={2020}
}

@inproceedings{kulkarni2015statistically,
  title={Statistically significant detection of linguistic change},
  author={Kulkarni, Vivek and Al-Rfou, Rami and Perozzi, Bryan and Skiena, Steven},
  booktitle={Proceedings of the 24th International Conference on World Wide Web},
  pages={625--635},
  year={2015}
}

@inproceedings{gupta-etal-2019-improving,
    title = "Improving Word Embeddings Using Kernel {PCA}",
    author = {Gupta, Vishwani  and
      Giesselbach, Sven  and
      R{\"u}ping, Stefan  and
      Bauckhage, Christian},
    booktitle = "Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4323",
    doi = "10.18653/v1/W19-4323",
    pages = "200--208",
    abstract = "Word-based embedding approaches such as Word2Vec capture the meaning of words and relations between them, particularly well when trained with large text collections; however, they fail to do so with small datasets. Extensions such as fastText reduce the amount of data needed slightly, however, the joint task of learning meaningful morphology, syntactic and semantic representations still requires a lot of data. In this paper, we introduce a new approach to warm-start embedding models with morphological information, in order to reduce training time and enhance their performance. We use word embeddings generated using both word2vec and fastText models and enrich them with morphological information of words, derived from kernel principal component analysis (KPCA) of word similarity matrices. This can be seen as explicitly feeding the network morphological similarities and letting it learn semantic and syntactic similarities. Evaluating our models on word similarity and analogy tasks in English and German, we find that they not only achieve higher accuracies than the original skip-gram and fastText models but also require significantly less training data and time. Another benefit of our approach is that it is capable of generating a high-quality representation of infrequent words as, for example, found in very recent news articles with rapidly changing vocabularies. Lastly, we evaluate the different models on a downstream sentence classification task in which a CNN model is initialized with our embeddings and find promising results.",
}

@incollection{NIPS2013_5165,
title = {Learning word embeddings efficiently with noise-contrastive estimation},
author = {Mnih, Andriy and Kavukcuoglu, Koray},
booktitle = {Advances in Neural Information Processing Systems 26},
editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
pages = {2265--2273},
year = {2013},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf}
}

@inproceedings{buck2014n,
  title={N-gram Counts and Language Models from the Common Crawl.},
  author={Buck, Christian and Heafield, Kenneth and Van Ooyen, Bas},
  booktitle={LREC},
  volume={2},
  pages={4},
  year={2014},
  organization={Citeseer}
}

@inproceedings{rehurek_lrec,
      title = {{Software Framework for Topic Modelling with Large Corpora}},
      author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
      booktitle = {{Proceedings of the LREC 2010 Workshop on New
           Challenges for NLP Frameworks}},
      pages = {45--50},
      year = 2010,
      month = May,
      day = 22,
      publisher = {ELRA},
      address = {Valletta, Malta},
      note={\url{http://is.muni.cz/publication/884893/en}},
      language={English}
}

@article{bojanowski2016enriching,
  title={Enriching Word Vectors with Subword Information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.04606},
  year={2016}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{felbo2017using,
  title={Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm},
  author={Felbo, Bjarke and Mislove, Alan and S{\o}gaard, Anders and Rahwan, Iyad and Lehmann, Sune},
  journal={arXiv preprint arXiv:1708.00524},
  year={2017}
}

@article{barbieri2017emojis,
  title={Are emojis predictable?},
  author={Barbieri, Francesco and Ballesteros, Miguel and Saggion, Horacio},
  journal={arXiv preprint arXiv:1702.07285},
  year={2017}
}

@inproceedings{ai2017untangling,
  title={Untangling emoji popularity through semantic embeddings},
  author={Ai, Wei and Lu, Xuan and Liu, Xuanzhe and Wang, Ning and Huang, Gang and Mei, Qiaozhu},
  booktitle={Eleventh International AAAI Conference on Web and Social Media},
  year={2017}
}

@inproceedings{barbieri2018semeval,
  title={Semeval 2018 task 2: Multilingual emoji prediction},
  author={Barbieri, Francesco and Camacho-Collados, Jose and Ronzano, Francesco and Anke, Luis Espinosa and Ballesteros, Miguel and Basile, Valerio and Patti, Viviana and Saggion, Horacio},
  booktitle={Proceedings of The 12th International Workshop on Semantic Evaluation},
  pages={24--33},
  year={2018}
}

@inproceedings{wijeratne2017semantics,
  title={A semantics-based measure of emoji similarity},
  author={Wijeratne, Sanjaya and Balasuriya, Lakshika and Sheth, Amit and Doran, Derek},
  booktitle={Proceedings of the International Conference on Web Intelligence},
  pages={646--653},
  year={2017}
}

@article{barbieri2018multimodal,
  title={Multimodal emoji prediction},
  author={Barbieri, Francesco and Ballesteros, Miguel and Ronzano, Francesco and Saggion, Horacio},
  journal={arXiv preprint arXiv:1803.02392},
  year={2018}
}

@inproceedings{al2019smile,
  title={Smile, be happy:) emoji embedding for visual sentiment analysis},
  author={Al-Halah, Ziad and Aitken, Andrew and Shi, Wenzhe and Caballero, Jose},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019}
}

@inproceedings{guntuku2019studying,
  title={Studying cultural differences in emoji usage across the east and the west},
  author={Guntuku, Sharath Chandra and Li, Mingyang and Tay, Louis and Ungar, Lyle H},
  booktitle={Proceedings of the International AAAI Conference on Web and Social Media},
  volume={13},
  pages={226--235},
  year={2019}
}

@article{jiang2018learningword,
  title={LearningWord Embeddings for Low-resource Languages by PU Learning},
  author={Jiang, Chao and Yu, Hsiang-Fu and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1805.03366},
  year={2018}
}

@inproceedings{finkelstein2001placing,
  title={Placing search in context: The concept revisited},
  author={Finkelstein, Lev and Gabrilovich, Evgeniy and Matias, Yossi and Rivlin, Ehud and Solan, Zach and Wolfman, Gadi and Ruppin, Eytan},
  booktitle={Proceedings of the 10th international conference on World Wide Web},
  pages={406--414},
  year={2001}
}

@inproceedings{zesch2008using,
  title={Using Wiktionary for Computing Semantic Relatedness.},
  author={Zesch, Torsten and M{\"u}ller, Christof and Gurevych, Iryna},
  year={2008}
}

@article{agirre2009study,
  title={A study on similarity and relatedness using distributional and wordnet-based approaches},
  author={Agirre, Eneko and Alfonseca, Enrique and Hall, Keith and Kravalova, Jana and Pasca, Marius and Soroa, Aitor},
  year={2009}
}

@inproceedings{radinsky2011word,
  title={A word at a time: computing word relatedness using temporal semantic analysis},
  author={Radinsky, Kira and Agichtein, Eugene and Gabrilovich, Evgeniy and Markovitch, Shaul},
  booktitle={Proceedings of the 20th international conference on World wide web},
  pages={337--346},
  year={2011}
}

@inproceedings{bruni2012distributional,
  title={Distributional semantics in technicolor},
  author={Bruni, Elia and Boleda, Gemma and Baroni, Marco and Tran, Nam-Khanh},
  booktitle={Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={136--145},
  year={2012}
}

@inproceedings{adams-etal-2017-cross,
    title = "Cross-Lingual Word Embeddings for Low-Resource Language Modeling",
    author = "Adams, Oliver  and
      Makarucha, Adam  and
      Neubig, Graham  and
      Bird, Steven  and
      Cohn, Trevor",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/E17-1088",
    pages = "937--947",
    abstract = "Most languages have no established writing system and minimal written records. However, textual data is essential for natural language processing, and particularly important for training language models to support speech recognition. Even in cases where text data is missing, there are some languages for which bilingual lexicons are available, since creating lexicons is a fundamental task of documentary linguistics. We investigate the use of such lexicons to improve language models when textual training data is limited to as few as a thousand sentences. The method involves learning cross-lingual word embeddings as a preliminary step in training monolingual language models. Results across a number of languages show that language models are improved by this pre-training. Application to Yongning Na, a threatened language, highlights challenges in deploying the approach in real low-resource environments.",
}

@inproceedings{jungmaier-etal-2020-dirichlet,
    title = "{D}irichlet-Smoothed Word Embeddings for Low-Resource Settings",
    author = "Jungmaier, Jakob  and
      Kassner, Nora  and
      Roth, Benjamin",
    booktitle = "Proceedings of The 12th Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://www.aclweb.org/anthology/2020.lrec-1.437",
    pages = "3560--3565",
    abstract = "Nowadays, classical count-based word embeddings using positive pointwise mutual information (PPMI) weighted co-occurrence matrices have been widely superseded by machine-learning-based methods like word2vec and GloVe. But these methods are usually applied using very large amounts of text data. In many cases, however, there is not much text data available, for example for specific domains or low-resource languages. This paper revisits PPMI by adding Dirichlet smoothing to correct its bias towards rare words. We evaluate on standard word similarity data sets and compare to word2vec and the recent state of the art for low-resource settings: Positive and Unlabeled (PU) Learning for word embeddings. The proposed method outperforms PU-Learning for low-resource settings and obtains competitive results for Maltese and Luxembourgish.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@inproceedings{michel-etal-2020-exploring,
    title = "Exploring Bilingual Word Embeddings for {H}iligaynon, a Low-Resource Language",
    author = "Michel, Leah  and
      Hangya, Viktor  and
      Fraser, Alexander",
    booktitle = "Proceedings of The 12th Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://www.aclweb.org/anthology/2020.lrec-1.313",
    pages = "2573--2580",
    abstract = "This paper investigates the use of bilingual word embeddings for mining Hiligaynon translations of English words. There is very little research on Hiligaynon, an extremely low-resource language of Malayo-Polynesian origin with over 9 million speakers in the Philippines (we found just one paper). We use a publicly available Hiligaynon corpus with only 300K words, and match it with a comparable corpus in English. As there are no bilingual resources available, we manually develop a English-Hiligaynon lexicon and use this to train bilingual word embeddings. But we fail to mine accurate translations due to the small amount of data. To find out if the same holds true for a related language pair, we simulate the same low-resource setup on English to German and arrive at similar results. We then vary the size of the comparable English and German corpora to determine the minimum corpus size necessary to achieve competitive results. Further, we investigate the role of the seed lexicon. We show that with the same corpus size but with a smaller seed lexicon, performance can surpass results of previous studies. We release the lexicon of 1,200 English-Hiligaynon word pairs we created to encourage further investigation.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@inproceedings{camacho-collados-navigli-2016-find,
    title = "Find the word that does not belong: A Framework for an Intrinsic Evaluation of Word Vector Representations",
    author = "Camacho-Collados, Jos{\'e}  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for {NLP}",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W16-2508",
    doi = "10.18653/v1/W16-2508",
    pages = "43--50",
}

@article{bergstra2012random,
  title={Random search for hyper-parameter optimization},
  author={Bergstra, James and Bengio, Yoshua},
  journal={The Journal of Machine Learning Research},
  volume={13},
  number={1},
  pages={281--305},
  year={2012},
  publisher={JMLR. org}
}

@article{wang2019evaluating,
  title={Evaluating word embedding models: Methods and experimental results},
  author={Wang, Bin and Wang, Angela and Chen, Fenxiao and Wang, Yuncheng and Kuo, C-C Jay},
  journal={APSIPA transactions on signal and information processing},
  volume={8},
  year={2019},
  publisher={Cambridge University Press}
}
